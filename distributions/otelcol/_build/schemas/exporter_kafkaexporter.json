{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "properties": {
    "auth": {
      "description": "Authentication holds Kafka authentication details.",
      "properties": {
        "kerberos": {
          "description": "Kerberos holds Kerberos authentication configuration.",
          "properties": {
            "config_file": {
              "type": "string"
            },
            "disable_fast_negotiation": {
              "type": "boolean"
            },
            "keytab_file": {
              "type": "string"
            },
            "password": {
              "type": "string"
            },
            "realm": {
              "type": "string"
            },
            "service_name": {
              "type": "string"
            },
            "use_keytab": {
              "type": "boolean"
            },
            "username": {
              "type": "string"
            }
          },
          "type": "object"
        },
        "plain_text": {
          "deprecated": true,
          "description": "PlainText is an alias for SASL/PLAIN authentication. Deprecated [v0.123.0]: use SASL with Mechanism set to PLAIN instead.",
          "properties": {
            "password": {
              "type": "string"
            },
            "username": {
              "type": "string"
            }
          },
          "type": "object"
        },
        "sasl": {
          "description": "SASL holds SASL authentication configuration.",
          "properties": {
            "aws_msk": {
              "description": "AWSMSK holds configuration specific to AWS MSK.",
              "properties": {
                "region": {
                  "description": "Region is the AWS region the MSK cluster is based in",
                  "type": "string"
                }
              },
              "type": "object"
            },
            "mechanism": {
              "description": "SASL Mechanism to be used, possible values are: (PLAIN, AWS_MSK_IAM_OAUTHBEARER, SCRAM-SHA-256 or SCRAM-SHA-512).",
              "type": "string"
            },
            "password": {
              "description": "Password to be used on authentication",
              "type": "string"
            },
            "username": {
              "description": "Username to be used on authentication",
              "type": "string"
            },
            "version": {
              "description": "SASL Protocol Version to be used, possible values are: (0, 1). Defaults to 0.",
              "type": "integer"
            }
          },
          "type": "object"
        },
        "tls": {
          "deprecated": true,
          "description": "TLS holds TLS configuration for connecting to Kafka brokers. Deprecated [v0.124.0]: use ClientConfig.TLS instead. This will be used only if ClientConfig.TLS is not set.",
          "properties": {
            "ca_file": {
              "description": "Path to the CA cert. For a client this verifies the server certificate. For a server this verifies client certificates. If empty uses system root CA. (optional)",
              "type": "string"
            },
            "ca_pem": {
              "description": "In memory PEM encoded cert. (optional)",
              "type": "string"
            },
            "cert_file": {
              "description": "Path to the TLS cert to use for TLS required connections. (optional)",
              "type": "string"
            },
            "cert_pem": {
              "description": "In memory PEM encoded TLS cert to use for TLS required connections. (optional)",
              "type": "string"
            },
            "cipher_suites": {
              "description": "CipherSuites is a list of TLS cipher suites that the TLS transport can use. If left blank, a safe default list is used. See https://go.dev/src/crypto/tls/cipher_suites.go for a list of supported cipher suites.",
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            "curve_preferences": {
              "description": "contains the elliptic curves that will be used in an ECDHE handshake, in preference order Defaults to empty list and \"crypto/tls\" defaults are used, internally.",
              "items": {
                "type": "string"
              },
              "type": "array"
            },
            "include_system_ca_certs_pool": {
              "description": "If true, load system CA certificates pool in addition to the certificates configured in this struct.",
              "type": "boolean"
            },
            "insecure": {
              "description": "In gRPC and HTTP when set to true, this is used to disable the client transport security. See https://godoc.org/google.golang.org/grpc#WithInsecure for gRPC. Please refer to https://godoc.org/crypto/tls#Config for more information. (optional, default false)",
              "type": "boolean"
            },
            "insecure_skip_verify": {
              "description": "InsecureSkipVerify will enable TLS but not verify the certificate.",
              "type": "boolean"
            },
            "key_file": {
              "description": "Path to the TLS key to use for TLS required connections. (optional)",
              "type": "string"
            },
            "key_pem": {
              "description": "In memory PEM encoded TLS key to use for TLS required connections. (optional)",
              "type": "string"
            },
            "max_version": {
              "description": "MaxVersion sets the maximum TLS version that is acceptable. If not set, refer to crypto/tls for defaults. (optional)",
              "type": "string"
            },
            "min_version": {
              "description": "MinVersion sets the minimum TLS version that is acceptable. If not set, TLS 1.2 will be used. (optional)",
              "type": "string"
            },
            "reload_interval": {
              "description": "ReloadInterval specifies the duration after which the certificate will be reloaded If not set, it will never be reloaded (optional)",
              "pattern": "^[0-9]+(ns|us|µs|ms|s|m|h)$",
              "type": "string"
            },
            "server_name_override": {
              "description": "ServerName requested by client for virtual hosting. This sets the ServerName in the TLSConfig. Please refer to https://godoc.org/crypto/tls#Config for more information. (optional)",
              "type": "string"
            },
            "tpm": {
              "description": "Trusted platform module configuration",
              "properties": {
                "auth": {
                  "type": "string"
                },
                "enabled": {
                  "type": "boolean"
                },
                "owner_auth": {
                  "type": "string"
                },
                "path": {
                  "description": "The path to the TPM device or Unix domain socket. For instance /dev/tpm0 or /dev/tpmrm0.",
                  "type": "string"
                }
              },
              "type": "object"
            }
          },
          "type": "object"
        }
      },
      "type": "object"
    },
    "brokers": {
      "description": "Brokers holds the list of Kafka bootstrap servers (default localhost:9092).",
      "items": {
        "type": "string"
      },
      "type": "array"
    },
    "client_id": {
      "description": "ClientID holds the client ID advertised to Kafka, which can be used for enforcing ACLs, throttling quotas, and more (default \"otel-collector\")",
      "type": "string"
    },
    "enabled": {
      "description": "Enabled indicates whether to not retry sending batches in case of export failure.",
      "type": "boolean"
    },
    "encoding": {
      "deprecated": true,
      "description": "Encoding holds the encoding of Kafka message values. Encoding has no default. If explicitly specified, it will take precedence over the default values of logs::encoding, metrics::encoding, and traces::encoding. Deprecated [v0.124.0]: use logs::encoding, metrics::encoding, and traces::encoding instead.",
      "type": "string"
    },
    "include_metadata_keys": {
      "description": "IncludeMetadataKeys indicates the receiver's client metadata keys to propagate as Kafka message headers.",
      "items": {
        "type": "string"
      },
      "type": "array"
    },
    "initial_interval": {
      "description": "InitialInterval the time to wait after the first failure before retrying.",
      "pattern": "^[0-9]+(ns|us|µs|ms|s|m|h)$",
      "type": "string"
    },
    "logs": {
      "description": "Logs holds configuration about how logs should be sent to Kafka.",
      "properties": {
        "encoding": {
          "description": "Encoding holds the encoding of messages for the signal type. Defaults to \"otlp_proto\".",
          "type": "string"
        },
        "topic": {
          "description": "Topic holds the name of the Kafka topic to which messages of the signal type should be produced. The default depends on the signal type: - \"otlp_spans\" for traces - \"otlp_metrics\" for metrics - \"otlp_logs\" for logs - \"otlp_profiles\" for profiles",
          "type": "string"
        },
        "topic_from_metadata_key": {
          "description": "TopicFromMetadataKey holds the name of the metadata key to use as the topic name for this signal type. If this is set, it takes precedence over the topic name set in the topic field.",
          "type": "string"
        }
      },
      "type": "object"
    },
    "max_elapsed_time": {
      "description": "MaxElapsedTime is the maximum amount of time (including retries) spent trying to send a request/batch. Once this value is reached, the data is discarded. If set to 0, the retries are never stopped.",
      "pattern": "^[0-9]+(ns|us|µs|ms|s|m|h)$",
      "type": "string"
    },
    "max_interval": {
      "description": "MaxInterval is the upper bound on backoff interval. Once this value is reached the delay between consecutive retries will always be `MaxInterval`.",
      "pattern": "^[0-9]+(ns|us|µs|ms|s|m|h)$",
      "type": "string"
    },
    "metadata": {
      "description": "Metadata holds metadata-related configuration for producers and consumers.",
      "properties": {
        "full": {
          "description": "Whether to maintain a full set of metadata for all topics, or just the minimal set that has been necessary so far. The full set is simpler and usually more convenient, but can take up a substantial amount of memory if you have many topics and partitions. Defaults to true.",
          "type": "boolean"
        },
        "refresh_interval": {
          "description": "RefreshInterval controls the frequency at which cluster metadata is refreshed. Defaults to 10 minutes.",
          "pattern": "^[0-9]+(ns|us|µs|ms|s|m|h)$",
          "type": "string"
        },
        "retry": {
          "description": "Retry configuration for metadata. This configuration is useful to avoid race conditions when broker is starting at the same time as collector.",
          "properties": {
            "backoff": {
              "description": "How long to wait for leader election to occur before retrying (default 250ms). Similar to the JVM's `retry.backoff.ms`.",
              "pattern": "^[0-9]+(ns|us|µs|ms|s|m|h)$",
              "type": "string"
            },
            "max": {
              "description": "The total number of times to retry a metadata request when the cluster is in the middle of a leader election or at startup (default 3).",
              "type": "integer"
            }
          },
          "type": "object"
        }
      },
      "type": "object"
    },
    "metrics": {
      "description": "Metrics holds configuration about how metrics should be sent to Kafka.",
      "properties": {
        "encoding": {
          "description": "Encoding holds the encoding of messages for the signal type. Defaults to \"otlp_proto\".",
          "type": "string"
        },
        "topic": {
          "description": "Topic holds the name of the Kafka topic to which messages of the signal type should be produced. The default depends on the signal type: - \"otlp_spans\" for traces - \"otlp_metrics\" for metrics - \"otlp_logs\" for logs - \"otlp_profiles\" for profiles",
          "type": "string"
        },
        "topic_from_metadata_key": {
          "description": "TopicFromMetadataKey holds the name of the metadata key to use as the topic name for this signal type. If this is set, it takes precedence over the topic name set in the topic field.",
          "type": "string"
        }
      },
      "type": "object"
    },
    "multiplier": {
      "description": "Multiplier is the value multiplied by the backoff interval bounds",
      "type": "number"
    },
    "partition_logs_by_resource_attributes": {
      "description": "PartitionLogsByResourceAttributes controls the partitioning of logs messages by resource. If this is true, then the message key will be set to a hash of the resource's identifying attributes.",
      "type": "boolean"
    },
    "partition_logs_by_trace_id": {
      "description": "PartitionLogsByTraceID controls partitioning of log messages by trace ID only. When enabled, the exporter splits incoming logs per TraceID (using SplitLogs) and sets the Kafka message key to the 16-byte hex string of that TraceID. If a LogRecord has an empty TraceID, the key may be empty and partition selection falls back to the Kafka client’s default strategy. Resource attributes are not used for the key when this option is enabled.",
      "type": "boolean"
    },
    "partition_metrics_by_resource_attributes": {
      "description": "PartitionMetricsByResourceAttributes controls the partitioning of metrics messages by resource. If this is true, then the message key will be set to a hash of the resource's identifying attributes.",
      "type": "boolean"
    },
    "partition_traces_by_id": {
      "description": "PartitionTracesByID sets the message key of outgoing trace messages to the trace ID. NOTE: this does not have any effect for Jaeger encodings. Jaeger encodings always use use the trace ID for the message key.",
      "type": "boolean"
    },
    "producer": {
      "properties": {
        "allow_auto_topic_creation": {
          "description": "Whether or not to allow automatic topic creation. (default enabled).",
          "type": "boolean"
        },
        "compression": {
          "description": "Compression Codec used to produce messages https://pkg.go.dev/github.com/IBM/sarama@v1.30.0#CompressionCodec The options are: 'none' (default), 'gzip', 'snappy', 'lz4', and 'zstd'",
          "type": "string"
        },
        "compression_params": {
          "description": "CompressionParams defines compression parameters for the producer.",
          "properties": {
            "level": {
              "type": "integer"
            }
          },
          "type": "object"
        },
        "flush_max_messages": {
          "description": "The maximum number of messages the producer will send in a single broker request. Defaults to 0 for unlimited. Similar to `queue.buffering.max.messages` in the JVM producer.",
          "type": "integer"
        },
        "linger": {
          "description": "Linger controls the linger time for the producer. (default 10ms).",
          "pattern": "^[0-9]+(ns|us|µs|ms|s|m|h)$",
          "type": "string"
        },
        "max_message_bytes": {
          "description": "Maximum message bytes the producer will accept to produce (default 1000000)",
          "type": "integer"
        },
        "required_acks": {
          "description": "RequiredAcks holds the number acknowledgements required before producing returns successfully. See: https://docs.confluent.io/platform/current/installation/configuration/producer-configs.html#acks Acceptable values are: 0 (NoResponse)   Does not wait for any acknowledgements. 1 (WaitForLocal) Waits for only the leader to write the record to its local log, but does not wait for followers to acknowledge. (default) -1 (WaitForAll)   Waits for all in-sync replicas to acknowledge. In YAML configuration, \"all\" is accepted as an alias for -1.",
          "type": "integer"
        }
      },
      "type": "object"
    },
    "profiles": {
      "description": "Profiles holds configuration about how profiles should be sent to Kafka.",
      "properties": {
        "encoding": {
          "description": "Encoding holds the encoding of messages for the signal type. Defaults to \"otlp_proto\".",
          "type": "string"
        },
        "topic": {
          "description": "Topic holds the name of the Kafka topic to which messages of the signal type should be produced. The default depends on the signal type: - \"otlp_spans\" for traces - \"otlp_metrics\" for metrics - \"otlp_logs\" for logs - \"otlp_profiles\" for profiles",
          "type": "string"
        },
        "topic_from_metadata_key": {
          "description": "TopicFromMetadataKey holds the name of the metadata key to use as the topic name for this signal type. If this is set, it takes precedence over the topic name set in the topic field.",
          "type": "string"
        }
      },
      "type": "object"
    },
    "protocol_version": {
      "description": "ProtocolVersion defines the Kafka protocol version that the client will assume it is running against.",
      "type": "string"
    },
    "rack_id": {
      "description": "RackID provides the rack identifier for this client to enable rack-aware replica selection when supported by the brokers. This maps to Kafka's standard \"client.rack\" setting. By default, this is empty.",
      "type": "string"
    },
    "randomization_factor": {
      "description": "RandomizationFactor is a random factor used to calculate next backoffs Randomized interval = RetryInterval * (1 ± RandomizationFactor)",
      "type": "number"
    },
    "resolve_canonical_bootstrap_servers_only": {
      "description": "ResolveCanonicalBootstrapServersOnly configures the Kafka client to perform a DNS lookup on each of the provided brokers, and then perform a reverse lookup on the resulting IPs to obtain the canonical hostnames to use as the bootstrap servers. This can be required in SASL environments.",
      "type": "boolean"
    },
    "sending_queue": {
      "type": "object"
    },
    "timeoutsettings": {
      "description": "squash ensures fields are correctly decoded in embedded struct.",
      "type": "object"
    },
    "tls": {
      "description": "TLS holds TLS-related configuration for connecting to Kafka brokers. By default the client will use an insecure connection unless SASL/AWS_MSK_IAM_OAUTHBEARER auth is configured.",
      "properties": {
        "ca_file": {
          "description": "Path to the CA cert. For a client this verifies the server certificate. For a server this verifies client certificates. If empty uses system root CA. (optional)",
          "type": "string"
        },
        "ca_pem": {
          "description": "In memory PEM encoded cert. (optional)",
          "type": "string"
        },
        "cert_file": {
          "description": "Path to the TLS cert to use for TLS required connections. (optional)",
          "type": "string"
        },
        "cert_pem": {
          "description": "In memory PEM encoded TLS cert to use for TLS required connections. (optional)",
          "type": "string"
        },
        "cipher_suites": {
          "description": "CipherSuites is a list of TLS cipher suites that the TLS transport can use. If left blank, a safe default list is used. See https://go.dev/src/crypto/tls/cipher_suites.go for a list of supported cipher suites.",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "curve_preferences": {
          "description": "contains the elliptic curves that will be used in an ECDHE handshake, in preference order Defaults to empty list and \"crypto/tls\" defaults are used, internally.",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "include_system_ca_certs_pool": {
          "description": "If true, load system CA certificates pool in addition to the certificates configured in this struct.",
          "type": "boolean"
        },
        "insecure": {
          "description": "In gRPC and HTTP when set to true, this is used to disable the client transport security. See https://godoc.org/google.golang.org/grpc#WithInsecure for gRPC. Please refer to https://godoc.org/crypto/tls#Config for more information. (optional, default false)",
          "type": "boolean"
        },
        "insecure_skip_verify": {
          "description": "InsecureSkipVerify will enable TLS but not verify the certificate.",
          "type": "boolean"
        },
        "key_file": {
          "description": "Path to the TLS key to use for TLS required connections. (optional)",
          "type": "string"
        },
        "key_pem": {
          "description": "In memory PEM encoded TLS key to use for TLS required connections. (optional)",
          "type": "string"
        },
        "max_version": {
          "description": "MaxVersion sets the maximum TLS version that is acceptable. If not set, refer to crypto/tls for defaults. (optional)",
          "type": "string"
        },
        "min_version": {
          "description": "MinVersion sets the minimum TLS version that is acceptable. If not set, TLS 1.2 will be used. (optional)",
          "type": "string"
        },
        "reload_interval": {
          "description": "ReloadInterval specifies the duration after which the certificate will be reloaded If not set, it will never be reloaded (optional)",
          "pattern": "^[0-9]+(ns|us|µs|ms|s|m|h)$",
          "type": "string"
        },
        "server_name_override": {
          "description": "ServerName requested by client for virtual hosting. This sets the ServerName in the TLSConfig. Please refer to https://godoc.org/crypto/tls#Config for more information. (optional)",
          "type": "string"
        },
        "tpm": {
          "description": "Trusted platform module configuration",
          "properties": {
            "auth": {
              "type": "string"
            },
            "enabled": {
              "type": "boolean"
            },
            "owner_auth": {
              "type": "string"
            },
            "path": {
              "description": "The path to the TPM device or Unix domain socket. For instance /dev/tpm0 or /dev/tpmrm0.",
              "type": "string"
            }
          },
          "type": "object"
        }
      },
      "type": "object"
    },
    "topic": {
      "deprecated": true,
      "description": "Topic holds the name of the Kafka topic to which data should be exported. Topic has no default. If explicitly specified, it will take precedence over the default values of logs::topic, metrics::topic, and traces::topic. Deprecated [v0.124.0]: use logs::topic, metrics::topic, and traces::topic instead.",
      "type": "string"
    },
    "topic_from_attribute": {
      "description": "TopicFromAttribute is the name of the attribute to use as the topic name.",
      "type": "string"
    },
    "traces": {
      "description": "Traces holds configuration about how traces should be sent to Kafka.",
      "properties": {
        "encoding": {
          "description": "Encoding holds the encoding of messages for the signal type. Defaults to \"otlp_proto\".",
          "type": "string"
        },
        "topic": {
          "description": "Topic holds the name of the Kafka topic to which messages of the signal type should be produced. The default depends on the signal type: - \"otlp_spans\" for traces - \"otlp_metrics\" for metrics - \"otlp_logs\" for logs - \"otlp_profiles\" for profiles",
          "type": "string"
        },
        "topic_from_metadata_key": {
          "description": "TopicFromMetadataKey holds the name of the metadata key to use as the topic name for this signal type. If this is set, it takes precedence over the topic name set in the topic field.",
          "type": "string"
        }
      },
      "type": "object"
    },
    "use_leader_epoch": {
      "description": "When enabled, the consumer uses the leader epoch returned by brokers (KIP-320) to detect log truncation. Setting this to false clears the leader epoch from fetch offsets, disabling KIP-320. Disabling can improve compatibility with brokers that don’t fully support leader epochs (e.g., Azure Event Hubs), at the cost of losing automatic log-truncation safety. NOTE: this is experimental and may be removed in a future release.",
      "type": "boolean"
    }
  },
  "type": "object"
}